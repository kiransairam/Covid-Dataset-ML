---
title: "Untitled"
output: html_document
date: "2023-04-06"
---

---
title: "Assignment_4_2"
output: html_document
date: "2023-04-05"
---

1. (2p) explore the overall structure of the dataset using the str() function. Get a summary statistics of each variable. Answer the following questions:
o How many observations do you have in the data?
o What is the type of each variable? Categorical ( nominal or ordinal) or continuous?
o Is there any missing value?
o Draw the histogram of count. Interpret what you see in the histogram

```{R}

bike_dataset = read.csv("C:/ML/bike.csv", header = TRUE)

summary(bike_dataset)
str(bike_dataset)

```

There are 10886 observations in the data.

datetime: character
season: integer (categorical)
holiday: integer (categorical)
workingday: integer (categorical)
weather: integer (categorical)
temp: numeric (continuous)
atemp: numeric (continuous)
humidity: integer (continuous)
windspeed: numeric (continuous)
casual: integer (continuous)
registered: integer (continuous)
count: integer (continuous)

```{R}

sum(is.na(bike_dataset))

```
There is no missing values.

```{R}
#install.packages("ggplot2")
library(ggplot2)

#ggplot(bike_dataset, aes(x = count)) + geom_histogram(binwidth = 50)

hist(bike_dataset$count)


```

2. Remove the “registered” and “casual” variables. These are the count of registered and casual users and together they can perfectly predict “count” so we are removing them from the model and predict count from the other features

```{R}

bike_dataset = subset(bike_dataset, select = -c(registered,casual) )

str(bike_dataset)

```
3. (1p) The count variable is severely right-skewed. A skewed target variable can make a machine learning model biased. For instance, in this case lower counts are more frequent in the training data compared to higher counts . Therefore, a machine learning model trained on this data is less likely to successfully predict higher counts. There are different ways we can transform a right-skewed variable to a more bell-shape distribution. Common transformations for a right-skewed data includes log, square-root and cube-root transformations. We are going to use square root transformation here to make the distribution of count more bell-shaped. Set the count variable in your dataframe equal to square root of count and plot its distribution again.


```{R}

bike_dataset$count = sqrt(bike_dataset$count)
hist(bike_dataset$count, col = "red", xlab = "Count square root", main = "Distribution of Count in square root ")

```

in the above we used the square root transformation


4. (2 pt) Variable datetime is not useful in its current form. Convert this variable to “day of month”, “year”, “day of week”, ”month” and “hour” variables. You can use as.POSIXlt function to extract those features from datetime. Please see this reference for an example.Remove the original datetime variable after conversion.

```{R}
# Convert character data to date and time.
#bike_dataset$datetime = as.POSIXct("2015-10-19 10:15")   
#str(bike_dataset$datetime)

# view sample data
head(bike_dataset$datetime)

# Convert character data to POSIXlt date and time
#timeDatelt<- as.POSIXlt("2015-10-19 10:15")  
#str(timeDatelt)

#bike_dataset$datetime = as.POSIXlt(""%Y-%m-%d %H:%M:%S"")
#str(bike_dataset$datetime)

bike_dataset$datetime <- as.POSIXlt(bike_dataset$datetime, format = "%Y-%m-%d %H:%M:%S")
str(bike_dataset$datetime)
#bike_dataset$datetime

unclass(bike_dataset$datetime)


```

```{R}

sum(is.na(bike_dataset$datetime$gmtoff))

sum(is.na(bike_dataset$datetime))


```

```{R}
bike_dataset$year = bike_dataset$datetime$year + 1900
bike_dataset$month = bike_dataset$datetime$mon + 1 
bike_dataset$day = bike_dataset$datetime$mday
bike_dataset$hour = bike_dataset$datetime$hour
bike_dataset$dayofaweek = bike_dataset$datetime$wday

```

By using the below points in the following like we added the years and months to the values produced by the POSIXlt

Months in POSIXlt
POSIXlt has a few quirks. First, the month values stored in the POSIXlt object use zero-based indexing. This means that month #1 (January) is stored as 0, and month #2 (February) is stored as 1. Notice in the output above, October is stored as the 9th month ($mon = 9).

Years in POSIXlt
Years are also stored differently in the POSIXlt class. Year values are stored using a base index value of 1900. Thus, 2015 is stored as 115 ($year = 115

115 years since 1900).

```{R}

bike_dataset = subset(bike_dataset, select = -c(datetime) )

str(bike_dataset)

```

```{R}
sum(is.na(bike_dataset))

```



5. (3pt) Variables “month”, “day of week”, “hour”, and “season” are categorical but they are also circular. This means these variables are periodic in nature. If we represent a circular variable like “month” with numeric indices 0-11 we are implying that the distance between month 10 (November) and month 11 (December) is much lower than the distance between month 11(December) and month 0 (January) which is not correct. At the other hand if we one-hotencode the “month” variable we are ignoring the chronological ordering between month values and assume that the distance between every two months is equal. A better way to represent these variables is to map each value into a point in a circle where the lowest value appears next to the largest value in the circle. For instance, we can transform the “month” variable by creating “x” and “y” coordinates of the point in such circle using sin and cosine transformations as follows

```{R}
bike_dataset$x_month = cos(2*pi*bike_dataset$month/max(bike_dataset$month))
bike_dataset$y_month = sin(2*pi*bike_dataset$month/max(bike_dataset$month))

bike_dataset$x_dayofaweek=cos(2*pi*bike_dataset$dayofaweek/max(bike_dataset$dayofaweek))
bike_dataset$y_dayofaweek=sin(2*pi*bike_dataset$dayofaweek/max(bike_dataset$dayofaweek))

bike_dataset$x_hour = cos(2*pi*bike_dataset$hour/max(bike_dataset$hour))
bike_dataset$y_hour = sin(2*pi*bike_dataset$hour/max(bike_dataset$hour))

bike_dataset$x_season = cos(2*pi*bike_dataset$season/max(bike_dataset$season))
bike_dataset$y_season = sin(2*pi*bike_dataset$season/max(bike_dataset$season))

bike_dataset$day = as.numeric(bike_dataset$day)

```

```{R}
bike_dataset = subset(bike_dataset, select = -c(month,dayofaweek,hour,season) )
str(bike_dataset)
```
```{R}

#install.packages("mltools")
library(mltools)
library(data.table)


bike_d = bike_dataset[, c('weather', 'temp', 'atemp', 'humidity', 'windspeed', 'year', 'day', 'x_month', 'y_month', 'x_dayofaweek', 'y_dayofaweek', 'x_hour', 'y_hour', 'x_season', 'y_season')]
bike_d = one_hot((bike_d))

bike_d$holiday = bike_dataset$holiday
bike_d$workingday = bike_dataset$workingday


#bike_y = bike_dataset$count

#bike_y$count = bike_dataset$count

#bike_y = data.frame(count = bike_dataset$count)

bike_d$count = bike_dataset$count

```

```{R}
str(bike_d)
#str(bike_y)

```

8. Use Caret’s “createDataPartition” method as follows to partition the dataset
into bikes_train, and bikes_test (use 90% for training and 10% for testing)

```{R}
library(caret)


inTrain = createDataPartition(bike_d$count, p = 0.9, list = FALSE)

bike_train = bike_d[inTrain, ]
bike_test = bike_d[-inTrain, ]

#bike_train_y = bike_y[inTrain, ]
#bike_test_y = bike_y[-inTrain, ]

```




```{R}

dim(bike_train)
dim(bike_test)

```



9. (1pt) Set.seed(1) and further divide the bikes_train data into 90% training and 10% validation using Caret’s “CreateDataPartition” function.

```{R}

#dim(bike_train_y)

```

```{R}

# library(caret)
# 
# set.seed(1)
# 
# inTrain = createDataPartition(bike_train_y$count, p = 0.9, list = FALSE)
# bike_train_x_2 = bike_train_x[inTrain,]
# bike_val_x = bike_train_x[-inTrain,]
# 
# bike_train_y_2 = bike_train_y[inTrain,]
# bike_val_y = bike_train_y[-inTrain,]

library(caret)
set.seed(1)

inTrain = createDataPartition(bike_train$count, p = 0.9, list = FALSE)
bike_train_new = bike_train[inTrain, ]
bike_validation = bike_train[-inTrain, ]



```

```{R}

dim(bike_train_new)
dim(bike_validation)

names(bike_train_new)
names(bike_validation)
names(bike_test)

str(bike_train_new)

```
```{R}
numeric_cols = c("weather", "temp", "atemp", "humidity", "windspeed", "year", "day", "holiday", "workingday")

col_means_train=attr(scale(bike_train_new [,numeric_cols]), "scaled:center")
col_stddevs_train=attr( scale(bike_train_new[,numeric_cols]), "scaled:scale")


bike_train_new[numeric_cols]= scale(bike_train_new[numeric_cols])
bike_test[numeric_cols]=scale(bike_test[numeric_cols], center = col_means_train, scale =col_stddevs_train)

bike_train_new[numeric_cols]= scale(bike_train_new[numeric_cols])
bike_validation[numeric_cols]=scale(bike_validation[numeric_cols], center = col_means_train, scale =col_stddevs_train)

```

```{R}
str(bike_train_new)
str(bike_test)
str(bike_validation)

names(bike_train_new)
names(bike_test)
names(bike_validation)
```



```{R}


# install.packages("keras")
# library(keras)
# #install_keras()
# library("keras")

#model = keras_model_sequential()


```

```{R}
#install.packages("magrittr") # package installations are only needed the first time you use it
#install.packages("dplyr")    # alternative installation of the %>%
library(magrittr) # needs to be run every time you start R and want to use %>%
library(dplyr)

```

```{R}
#install.packages("keras")
library(keras)
#install_keras()
library("keras")

```

```{R}
library(reticulate)
#path_to_python <- install_python()
#virtualenv_create("r-reticulate", python = path_to_python)

library(tensorflow)
#install_tensorflow(envname = "r-reticulate")

```

```{R}
#install.packages("keras")
library(keras)
#install_keras(envname = "r-reticulate")

```

```{R}

library(tensorflow)
tf$constant("Hello Tensorflow!")

```

```{R}
# #install.packages("devtools")
# library(devtools)
# #
# devtools::install_github("rstudio/tensorflow")
# devtools::install_github("rstudio/keras")
# #
# tensorflow::install_tensorflow()
# tensorflow::tf_config()
#
# #install.packages("tensorflow")
# library(tensorflow)
# #install_tensorflow()

#install.packages("tfruns")

```

```{R}

set.seed(1)
train_bike_x <- bike_train_new[, -18]
train_bike_y <- bike_train_new[, 18]
val_bike_x <- bike_validation[,-18]
val_bike_y <- bike_validation[, 18]
test_bike_x <- bike_test[, -18]
test_bike_y <- bike_test[, 18]

```

```{R}
dim(train_bike_x)
dim(val_bike_x)
dim(test_bike_x)
# names(train_labels)
#dim(train_bike_y)
str(train_bike_y)
str(val_bike_y)
str(test_bike_y)

```

11. (5 pt) Create an ANN model to predict count from other attributes. Use at least two hidden layers. Use tfruns to tune your model’s hyper-parameters including, the number of nodes in each hidden layer, the activation function in each hidden layer, batch_size, learning_rate, and the number of epochs). Validate each model on the validation set.

```{R}
library(keras)
library(tensorflow)
library(tfruns)

set.seed(2)
#install.packages("tfruns")
library(keras)
library(tfruns)

FLAGS <- flags(
  flag_numeric("nodes", 8),
  flag_numeric("batch_size", 10),
  flag_string("activation", "relu"),
  flag_numeric("learning_rate", 0.01),
  flag_numeric("epochs", 30)
) 

model =keras_model_sequential() 

model %>%
  layer_dense(units=128, activation="relu", input_shape=dim(train_bike_x)[2])%>%
  layer_dropout(0.2)%>%
  layer_dense(units=128, activation="relu")%>%
  layer_dropout(0.2) %>%
  layer_dense(units=1)



model

```

```{R}
model %>% compile(
  loss = "mse",
  optimizer = "adam",
  metrics = list("mean_absolute_error")
)

model %>% summary()

```



```{R}
model %>% fit(as.matrix(train_bike_x), 
              train_bike_y,
              batch_size=10,
              epochs = 30,
              validation_data=list(as.matrix(val_bike_x),
                                             val_bike_y))

```

```{R}
set.seed(1)
model %>% evaluate(as.matrix(train_bike_x), train_bike_y)

```


```{R}

set.seed(1)

runs <- tuning_run("C:/ML/bikess.R", 
  flags = list(
  nodes = c(64, 128, 392),
  learning_rate = c(0.01, 0.05, 0.001, 0.0001), 
  batch_size=c(100,200,500,1000),
  epochs=c(30,50, 100),
  activation=c("relu","sigmoid", "tanh")),
  sample = 0.02
)

```

```{R}

view_run(runs$run_dir[1])

```

12. (5 pt) Measure the performance of your best model (after tuning) on the test set and compute its RMSE. Note that you must reverse the square root transformation by taking the square of the predictions returned by the neural network model and compare it to the original count value ( without square root
transformation). Doing this, helps us get the RMSE in the original scale.

```{R}


predictions=model %>% predict(as.matrix(test_bike_x))

```

```{R}

test_preds_sq = predictions^2

```

```{R}
test_rmse = sqrt(mean((test_preds_sq - test_bike_y)^2))

```

```{R}
cat("Test RMSE in original scale:", test_rmse, "\n")

```

13. (5 pt) Use a simple ( or step wise) linear regression model to predict the count. Train and test your model on the same data you used to train and test your best neural network model. Compare the RMSE of the linear model on the test data with the RMSE of the neural network model. How does your neural network model compare to a simple linear model?

```{R}
linear_model = lm(count ~ ., data = bike_train_new)
linear_preds = predict(linear_model, newdata = bike_test)
linear_rmse = sqrt(mean((bike_test$count - linear_preds)^2))
print(paste0("Linear regression RMSE: ", linear_rmse))
```